{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPHpTNd_Ssq-"
      },
      "source": [
        "# LTSM\n",
        "\n",
        "based on https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dczkbG4SSsrV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "#!conda install --yes --prefix {sys.prefix} tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tTZs0CBvSsrn"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from tensorflow.keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5wy6EFYgSsr4"
      },
      "outputs": [],
      "source": [
        "# load text and covert to lowercase\n",
        "filename = \"Bowie.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hHPU9yhnSsr6"
      },
      "outputs": [],
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: ' ',\n",
              " 2: '!',\n",
              " 3: '\"',\n",
              " 4: '&',\n",
              " 5: \"'\",\n",
              " 6: '(',\n",
              " 7: ')',\n",
              " 8: '*',\n",
              " 9: ',',\n",
              " 10: '-',\n",
              " 11: '.',\n",
              " 12: '/',\n",
              " 13: '0',\n",
              " 14: '1',\n",
              " 15: '2',\n",
              " 16: '3',\n",
              " 17: '4',\n",
              " 18: '5',\n",
              " 19: '6',\n",
              " 20: '7',\n",
              " 21: '8',\n",
              " 22: '9',\n",
              " 23: ':',\n",
              " 24: ';',\n",
              " 25: '?',\n",
              " 26: '[',\n",
              " 27: ']',\n",
              " 28: '_',\n",
              " 29: 'a',\n",
              " 30: 'b',\n",
              " 31: 'c',\n",
              " 32: 'd',\n",
              " 33: 'e',\n",
              " 34: 'f',\n",
              " 35: 'g',\n",
              " 36: 'h',\n",
              " 37: 'i',\n",
              " 38: 'j',\n",
              " 39: 'k',\n",
              " 40: 'l',\n",
              " 41: 'm',\n",
              " 42: 'n',\n",
              " 43: 'o',\n",
              " 44: 'p',\n",
              " 45: 'q',\n",
              " 46: 'r',\n",
              " 47: 's',\n",
              " 48: 't',\n",
              " 49: 'u',\n",
              " 50: 'v',\n",
              " 51: 'w',\n",
              " 52: 'x',\n",
              " 53: 'y',\n",
              " 54: 'z',\n",
              " 55: '{',\n",
              " 56: '}',\n",
              " 57: 'ß',\n",
              " 58: 'à',\n",
              " 59: 'ä',\n",
              " 60: 'è',\n",
              " 61: 'é',\n",
              " 62: 'ê',\n",
              " 63: 'ñ',\n",
              " 64: 'ò',\n",
              " 65: 'ô',\n",
              " 66: 'ö',\n",
              " 67: 'ù',\n",
              " 68: 'ü'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int_to_char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkc1xvReSssP",
        "outputId": "f89401bf-a26f-4ed8-83de-17d14b85254c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Characters:  950732\n",
            "Total Vocab (Different characters):  69\n",
            "Total Patterns:  950632\n"
          ]
        }
      ],
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab (Different characters): \", n_vocab)\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[43,\n",
              " 36,\n",
              " 1,\n",
              " 44,\n",
              " 37,\n",
              " 48,\n",
              " 53,\n",
              " 1,\n",
              " 49,\n",
              " 47,\n",
              " 1,\n",
              " 36,\n",
              " 33,\n",
              " 46,\n",
              " 33,\n",
              " 1,\n",
              " 51,\n",
              " 33,\n",
              " 1,\n",
              " 29,\n",
              " 42,\n",
              " 35,\n",
              " 33,\n",
              " 40,\n",
              " 47,\n",
              " 1,\n",
              " 43,\n",
              " 34,\n",
              " 1,\n",
              " 40,\n",
              " 33,\n",
              " 29,\n",
              " 32,\n",
              " 0,\n",
              " 51,\n",
              " 33,\n",
              " 5,\n",
              " 46,\n",
              " 33,\n",
              " 1,\n",
              " 32,\n",
              " 33,\n",
              " 29,\n",
              " 32,\n",
              " 9,\n",
              " 1,\n",
              " 51,\n",
              " 33,\n",
              " 5,\n",
              " 46,\n",
              " 33,\n",
              " 1,\n",
              " 47,\n",
              " 37,\n",
              " 31,\n",
              " 39,\n",
              " 1,\n",
              " 36,\n",
              " 29,\n",
              " 42,\n",
              " 35,\n",
              " 37,\n",
              " 42,\n",
              " 35,\n",
              " 1,\n",
              " 30,\n",
              " 53,\n",
              " 1,\n",
              " 48,\n",
              " 36,\n",
              " 46,\n",
              " 33,\n",
              " 29,\n",
              " 32,\n",
              " 0,\n",
              " 35,\n",
              " 33,\n",
              " 48,\n",
              " 1,\n",
              " 46,\n",
              " 33,\n",
              " 29,\n",
              " 40,\n",
              " 0,\n",
              " 35,\n",
              " 33,\n",
              " 48,\n",
              " 1,\n",
              " 46,\n",
              " 33,\n",
              " 29,\n",
              " 40,\n",
              " 0,\n",
              " 53,\n",
              " 43,\n",
              " 49,\n",
              " 1,\n",
              " 31,\n",
              " 29,\n",
              " 42]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataX[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sZg9866XSssU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = to_categorical(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(950632, 100, 1)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ddeS52R5SssW"
      },
      "outputs": [],
      "source": [
        "# define the LSTM model with Keras\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement3-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2otzkcdSssm",
        "outputId": "005995b9-8369-44a4-83b0-718134f10a11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 256)               264192    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               25700     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 69)                6969      \n",
            "=================================================================\n",
            "Total params: 296,861\n",
            "Trainable params: 296,861\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nLqkXcEGSssp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3169/3169 [==============================] - 24s 7ms/step - loss: 1.9164\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.91644, saving model to weights-improvement3-01-1.9164.hdf5\n",
            "Epoch 2/100\n",
            "3169/3169 [==============================] - 22s 7ms/step - loss: 1.8623\n",
            "\n",
            "Epoch 00002: loss improved from 1.91644 to 1.86233, saving model to weights-improvement3-02-1.8623.hdf5\n",
            "Epoch 3/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.8793\n",
            "\n",
            "Epoch 00003: loss did not improve from 1.86233\n",
            "Epoch 4/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.8138\n",
            "\n",
            "Epoch 00004: loss improved from 1.86233 to 1.81375, saving model to weights-improvement3-04-1.8138.hdf5\n",
            "Epoch 5/100\n",
            "3169/3169 [==============================] - 25s 8ms/step - loss: 1.8022\n",
            "\n",
            "Epoch 00005: loss improved from 1.81375 to 1.80215, saving model to weights-improvement3-05-1.8022.hdf5\n",
            "Epoch 6/100\n",
            "3169/3169 [==============================] - 25s 8ms/step - loss: 1.7812\n",
            "\n",
            "Epoch 00006: loss improved from 1.80215 to 1.78124, saving model to weights-improvement3-06-1.7812.hdf5\n",
            "Epoch 7/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.7573\n",
            "\n",
            "Epoch 00007: loss improved from 1.78124 to 1.75733, saving model to weights-improvement3-07-1.7573.hdf5\n",
            "Epoch 8/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.9351\n",
            "\n",
            "Epoch 00008: loss did not improve from 1.75733\n",
            "Epoch 9/100\n",
            "3169/3169 [==============================] - 25s 8ms/step - loss: 2.0099\n",
            "\n",
            "Epoch 00009: loss did not improve from 1.75733\n",
            "Epoch 10/100\n",
            "3169/3169 [==============================] - 25s 8ms/step - loss: 1.7517\n",
            "\n",
            "Epoch 00010: loss improved from 1.75733 to 1.75175, saving model to weights-improvement3-10-1.7517.hdf5\n",
            "Epoch 11/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.8173\n",
            "\n",
            "Epoch 00011: loss did not improve from 1.75175\n",
            "Epoch 12/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.7373\n",
            "\n",
            "Epoch 00012: loss improved from 1.75175 to 1.73730, saving model to weights-improvement3-12-1.7373.hdf5\n",
            "Epoch 13/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.7597\n",
            "\n",
            "Epoch 00013: loss did not improve from 1.73730\n",
            "Epoch 14/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.7053\n",
            "\n",
            "Epoch 00014: loss improved from 1.73730 to 1.70531, saving model to weights-improvement3-14-1.7053.hdf5\n",
            "Epoch 15/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.7041\n",
            "\n",
            "Epoch 00015: loss improved from 1.70531 to 1.70408, saving model to weights-improvement3-15-1.7041.hdf5\n",
            "Epoch 16/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.6820\n",
            "\n",
            "Epoch 00016: loss improved from 1.70408 to 1.68201, saving model to weights-improvement3-16-1.6820.hdf5\n",
            "Epoch 17/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.6631\n",
            "\n",
            "Epoch 00017: loss improved from 1.68201 to 1.66315, saving model to weights-improvement3-17-1.6631.hdf5\n",
            "Epoch 18/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.7477\n",
            "\n",
            "Epoch 00018: loss did not improve from 1.66315\n",
            "Epoch 19/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.7677\n",
            "\n",
            "Epoch 00019: loss did not improve from 1.66315\n",
            "Epoch 20/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.6427\n",
            "\n",
            "Epoch 00020: loss improved from 1.66315 to 1.64267, saving model to weights-improvement3-20-1.6427.hdf5\n",
            "Epoch 21/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.6954\n",
            "\n",
            "Epoch 00021: loss did not improve from 1.64267\n",
            "Epoch 22/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.7139\n",
            "\n",
            "Epoch 00022: loss did not improve from 1.64267\n",
            "Epoch 23/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.6373\n",
            "\n",
            "Epoch 00023: loss improved from 1.64267 to 1.63730, saving model to weights-improvement3-23-1.6373.hdf5\n",
            "Epoch 24/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.6174\n",
            "\n",
            "Epoch 00024: loss improved from 1.63730 to 1.61740, saving model to weights-improvement3-24-1.6174.hdf5\n",
            "Epoch 25/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.6251\n",
            "\n",
            "Epoch 00025: loss did not improve from 1.61740\n",
            "Epoch 26/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.6012\n",
            "\n",
            "Epoch 00026: loss improved from 1.61740 to 1.60119, saving model to weights-improvement3-26-1.6012.hdf5\n",
            "Epoch 27/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.9850\n",
            "\n",
            "Epoch 00027: loss did not improve from 1.60119\n",
            "Epoch 28/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.7081\n",
            "\n",
            "Epoch 00028: loss did not improve from 1.60119\n",
            "Epoch 29/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 2.2494\n",
            "\n",
            "Epoch 00029: loss did not improve from 1.60119\n",
            "Epoch 30/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 2.7646\n",
            "\n",
            "Epoch 00030: loss did not improve from 1.60119\n",
            "Epoch 31/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 2.6767\n",
            "\n",
            "Epoch 00031: loss did not improve from 1.60119\n",
            "Epoch 32/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 2.5740\n",
            "\n",
            "Epoch 00032: loss did not improve from 1.60119\n",
            "Epoch 33/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 2.4693\n",
            "\n",
            "Epoch 00033: loss did not improve from 1.60119\n",
            "Epoch 34/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 2.3352\n",
            "\n",
            "Epoch 00034: loss did not improve from 1.60119\n",
            "Epoch 35/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 2.2180\n",
            "\n",
            "Epoch 00035: loss did not improve from 1.60119\n",
            "Epoch 36/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 2.1173\n",
            "\n",
            "Epoch 00036: loss did not improve from 1.60119\n",
            "Epoch 37/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 2.0442\n",
            "\n",
            "Epoch 00037: loss did not improve from 1.60119\n",
            "Epoch 38/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.9836\n",
            "\n",
            "Epoch 00038: loss did not improve from 1.60119\n",
            "Epoch 39/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.9394\n",
            "\n",
            "Epoch 00039: loss did not improve from 1.60119\n",
            "Epoch 40/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.8972\n",
            "\n",
            "Epoch 00040: loss did not improve from 1.60119\n",
            "Epoch 41/100\n",
            "3169/3169 [==============================] - 24s 8ms/step - loss: 1.8640\n",
            "\n",
            "Epoch 00041: loss did not improve from 1.60119\n",
            "Epoch 42/100\n",
            " 435/3169 [===>..........................] - ETA: 20s - loss: 1.8459"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6372\\3366780163.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\HP.DESKTOP-G8GFKGS\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 _r=1):\n\u001b[0;32m   1192\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\HP.DESKTOP-G8GFKGS\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\HP.DESKTOP-G8GFKGS\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\HP.DESKTOP-G8GFKGS\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\HP.DESKTOP-G8GFKGS\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\HP.DESKTOP-G8GFKGS\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[1;32mc:\\Users\\HP.DESKTOP-G8GFKGS\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ALERT: very computationally expensive!\n",
        "\n",
        "# load the network weights\n",
        "filename = \"./weights-improvement3-09-1.9255.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=300, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAcdKEwSSstO"
      },
      "outputs": [],
      "source": [
        "# pick a random seed\n",
        "# start = numpy.random.randint(0, len(dataX)-1)\n",
        "# pattern = dataX[start]\n",
        "# print(\"Seed:\")\n",
        "# print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# # generate characters\n",
        "# for i in range(1000):\n",
        "#     x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "#     x = x / float(n_vocab)\n",
        "#     prediction = model.predict(x, verbose=0)\n",
        "#     index = numpy.argmax(prediction)\n",
        "#     result = int_to_char[index]\n",
        "#     seq_in = [int_to_char[value] for value in pattern]\n",
        "#     sys.stdout.write(result)\n",
        "#     pattern.append(index)\n",
        "#     pattern = pattern[1:len(pattern)]\n",
        "# print(\"\\nDone.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7kPh2yQSstT",
        "outputId": "81f0f70d-c484-475a-8448-b91320cfeb83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" to stay\n",
            "oh, you pretty things (oh, you pretty things)\n",
            "don't you know you're driving your mamas and p \"\n",
            "---------\n",
            "apas insane\n",
            "oh, you pretty things (oh, you pretty things)\n",
            "gond thar you're goyna bete mo to the goas the say the gone the sase the sas the say the say the wald\n",
            "the say thet well the say the walte the sas the say i mote you\n",
            "wouldn the walds the said the say the was the said\n",
            "the say the walts the say i was she soeee th the saie the sas the say the walds and the shar whlh the say what she saadees wou thet then the sase th the say th the sai the sas the say the wall\n",
            "the say the walt\n",
            "and the seadeee of the saie\n",
            "the say the wast th she soeee th the saie the sas th the sore the say i was she soeee th the saie the say th the soeee th the say the wald\n",
            "the was the sooe the say i was she sail so the shine she saie the say to she sooe the say the wast th the say the wald\n",
            "the say wou dotld lote\n",
            "then you raae i'm soeer thing the seee the sas the say the walds and the saie the say i was she soeee th the saie the say tha sas the wald\n",
            "the say the way the say i mev the shadees and these she say the say \n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# define the LSTM model with Keras\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "# load the network weights\n",
        "filename = \"./weights-improvement3-26-1.6012.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "print(\"---------\")\n",
        "\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sDYzNtHSstX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
